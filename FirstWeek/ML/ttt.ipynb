{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 回归模型演示\n",
    "使用梯度下降找到心心念念的两个参数 w 和 b\n",
    "### 引入相关库，为演示做好准备"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pylab import mpl\n",
    "# matplotlib没有中文字体，动态解决\n",
    "plt.rcParams['font.sans-serif'] = ['Simhei']  # 显示中文\n",
    "mpl.rcParams['axes.unicode_minus'] = False  # 解决保存图像是负号'-'显示为方块的问题"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 导入数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-200 -199 -198 ... -103 -102 -101]\n",
      " [-200 -199 -198 ... -103 -102 -101]\n",
      " [-200 -199 -198 ... -103 -102 -101]\n",
      " ...\n",
      " [-200 -199 -198 ... -103 -102 -101]\n",
      " [-200 -199 -198 ... -103 -102 -101]\n",
      " [-200 -199 -198 ... -103 -102 -101]] [[-5.  -5.  -5.  ... -5.  -5.  -5. ]\n",
      " [-4.9 -4.9 -4.9 ... -4.9 -4.9 -4.9]\n",
      " [-4.8 -4.8 -4.8 ... -4.8 -4.8 -4.8]\n",
      " ...\n",
      " [ 4.7  4.7  4.7 ...  4.7  4.7  4.7]\n",
      " [ 4.8  4.8  4.8 ...  4.8  4.8  4.8]\n",
      " [ 4.9  4.9  4.9 ...  4.9  4.9  4.9]]\n"
     ]
    }
   ],
   "source": [
    "x_data = [338., 333., 328., 207., 226., 25., 179., 60., 208., 606.]\n",
    "y_data = [640., 633., 619., 393., 428., 27., 193., 66., 226., 1591.]\n",
    "x_d = np.asarray(x_data)\n",
    "y_d = np.asarray(y_data)\n",
    "x = np.arange(-200, -100, 1)\n",
    "y = np.arange(-5, 5, 0.1)\n",
    "Z = np.zeros((len(x), len(y)))\n",
    "X, Y = np.meshgrid(x, y)\n",
    "print(X,Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 计算损失函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss\n",
    "for i in range(len(x)):\n",
    "    for j in range(len(y)):\n",
    "        b = x[i]\n",
    "        w = y[j]\n",
    "        Z[j][i] = 0  # meshgrid吐出结果：y为行，x为列\n",
    "        for n in range(len(x_data)):\n",
    "            Z[j][i] += (y_data[n] - b - w * x_data[n]) ** 2\n",
    "        Z[j][i] /= len(x_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 计算b和w的偏微分 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 0, w: 1.6534, b: -119.9839, Loss: 3670819.0000\n",
      "Step 10000, w: 2.4781, b: -121.8628, Loss: 11428.6652\n",
      "Step 20000, w: 2.4834, b: -123.6924, Loss: 11361.7161\n",
      "Step 30000, w: 2.4885, b: -125.4716, Loss: 11298.3964\n",
      "Step 40000, w: 2.4935, b: -127.2020, Loss: 11238.5092\n",
      "Step 50000, w: 2.4983, b: -128.8848, Loss: 11181.8685\n",
      "Step 60000, w: 2.5030, b: -130.5213, Loss: 11128.2983\n",
      "Step 70000, w: 2.5076, b: -132.1129, Loss: 11077.6321\n",
      "Step 80000, w: 2.5120, b: -133.6607, Loss: 11029.7126\n",
      "Step 90000, w: 2.5164, b: -135.1660, Loss: 10984.3908\n",
      "Step 100000, w: 2.5206, b: -136.6300, Loss: 10941.5259\n",
      "Step 110000, w: 2.5247, b: -138.0536, Loss: 10900.9847\n",
      "Step 120000, w: 2.5287, b: -139.4382, Loss: 10862.6412\n",
      "Step 130000, w: 2.5325, b: -140.7847, Loss: 10826.3764\n",
      "Step 140000, w: 2.5363, b: -142.0942, Loss: 10792.0774\n",
      "Step 150000, w: 2.5399, b: -143.3678, Loss: 10759.6379\n",
      "Step 160000, w: 2.5435, b: -144.6063, Loss: 10728.9568\n",
      "Step 170000, w: 2.5470, b: -145.8108, Loss: 10699.9390\n",
      "Step 180000, w: 2.5503, b: -146.9821, Loss: 10672.4943\n",
      "Step 190000, w: 2.5536, b: -148.1213, Loss: 10646.5373\n",
      "Step 200000, w: 2.5568, b: -149.2292, Loss: 10621.9875\n",
      "Step 210000, w: 2.5599, b: -150.3066, Loss: 10598.7685\n",
      "Step 220000, w: 2.5629, b: -151.3545, Loss: 10576.8082\n",
      "Step 230000, w: 2.5658, b: -152.3735, Loss: 10556.0384\n",
      "Step 240000, w: 2.5687, b: -153.3645, Loss: 10536.3946\n",
      "Step 250000, w: 2.5714, b: -154.3283, Loss: 10517.8156\n",
      "Step 260000, w: 2.5741, b: -155.2656, Loss: 10500.2438\n",
      "Step 270000, w: 2.5768, b: -156.1771, Loss: 10483.6245\n",
      "Step 280000, w: 2.5793, b: -157.0636, Loss: 10467.9062\n",
      "Step 290000, w: 2.5818, b: -157.9257, Loss: 10453.0400\n",
      "Step 300000, w: 2.5842, b: -158.7642, Loss: 10438.9797\n",
      "Step 310000, w: 2.5865, b: -159.5795, Loss: 10425.6816\n",
      "Step 320000, w: 2.5888, b: -160.3725, Loss: 10413.1044\n",
      "Step 330000, w: 2.5910, b: -161.1437, Loss: 10401.2090\n",
      "Step 340000, w: 2.5932, b: -161.8937, Loss: 10389.9584\n",
      "Step 350000, w: 2.5953, b: -162.6231, Loss: 10379.3178\n",
      "Step 360000, w: 2.5973, b: -163.3324, Loss: 10369.2539\n",
      "Step 370000, w: 2.5993, b: -164.0222, Loss: 10359.7357\n",
      "Step 380000, w: 2.6012, b: -164.6931, Loss: 10350.7334\n",
      "Step 390000, w: 2.6031, b: -165.3456, Loss: 10342.2191\n",
      "Step 400000, w: 2.6049, b: -165.9801, Loss: 10334.1664\n",
      "Step 410000, w: 2.6067, b: -166.5971, Loss: 10326.5503\n",
      "Step 420000, w: 2.6084, b: -167.1973, Loss: 10319.3470\n",
      "Step 430000, w: 2.6101, b: -167.7809, Loss: 10312.5342\n",
      "Step 440000, w: 2.6117, b: -168.3485, Loss: 10306.0907\n",
      "Step 450000, w: 2.6133, b: -168.9004, Loss: 10299.9965\n",
      "Step 460000, w: 2.6149, b: -169.4373, Loss: 10294.2327\n",
      "Step 470000, w: 2.6164, b: -169.9593, Loss: 10288.7813\n",
      "Step 480000, w: 2.6178, b: -170.4670, Loss: 10283.6255\n",
      "Step 490000, w: 2.6192, b: -170.9608, Loss: 10278.7492\n",
      "Step 500000, w: 2.6206, b: -171.4410, Loss: 10274.1372\n",
      "Step 510000, w: 2.6220, b: -171.9080, Loss: 10269.7752\n",
      "Step 520000, w: 2.6233, b: -172.3621, Loss: 10265.6497\n",
      "Step 530000, w: 2.6245, b: -172.8038, Loss: 10261.7478\n",
      "Step 540000, w: 2.6258, b: -173.2333, Loss: 10258.0575\n",
      "Step 550000, w: 2.6270, b: -173.6511, Loss: 10254.5672\n",
      "Step 560000, w: 2.6281, b: -174.0573, Loss: 10251.2661\n",
      "Step 570000, w: 2.6293, b: -174.4524, Loss: 10248.1440\n",
      "Step 580000, w: 2.6304, b: -174.8366, Loss: 10245.1911\n",
      "Step 590000, w: 2.6315, b: -175.2103, Loss: 10242.3983\n",
      "Step 600000, w: 2.6325, b: -175.5737, Loss: 10239.7569\n",
      "Step 610000, w: 2.6335, b: -175.9271, Loss: 10237.2587\n",
      "Step 620000, w: 2.6345, b: -176.2708, Loss: 10234.8959\n",
      "Step 630000, w: 2.6355, b: -176.6051, Loss: 10232.6612\n",
      "Step 640000, w: 2.6364, b: -176.9302, Loss: 10230.5476\n",
      "Step 650000, w: 2.6373, b: -177.2463, Loss: 10228.5487\n",
      "Step 660000, w: 2.6382, b: -177.5537, Loss: 10226.6580\n",
      "Step 670000, w: 2.6390, b: -177.8527, Loss: 10224.8699\n",
      "Step 680000, w: 2.6399, b: -178.1435, Loss: 10223.1787\n",
      "Step 690000, w: 2.6407, b: -178.4263, Loss: 10221.5792\n",
      "Step 700000, w: 2.6415, b: -178.7013, Loss: 10220.0664\n",
      "Step 710000, w: 2.6423, b: -178.9688, Loss: 10218.6356\n",
      "Step 720000, w: 2.6430, b: -179.2289, Loss: 10217.2824\n",
      "Step 730000, w: 2.6437, b: -179.4818, Loss: 10216.0025\n",
      "Step 740000, w: 2.6444, b: -179.7278, Loss: 10214.7920\n",
      "Step 750000, w: 2.6451, b: -179.9671, Loss: 10213.6472\n",
      "Step 760000, w: 2.6458, b: -180.1998, Loss: 10212.5644\n",
      "Step 770000, w: 2.6464, b: -180.4260, Loss: 10211.5403\n",
      "Step 780000, w: 2.6471, b: -180.6461, Loss: 10210.5717\n",
      "Step 790000, w: 2.6477, b: -180.8601, Loss: 10209.6556\n",
      "Step 800000, w: 2.6483, b: -181.0682, Loss: 10208.7892\n",
      "Step 810000, w: 2.6489, b: -181.2707, Loss: 10207.9697\n",
      "Step 820000, w: 2.6494, b: -181.4675, Loss: 10207.1947\n",
      "Step 830000, w: 2.6500, b: -181.6589, Loss: 10206.4617\n",
      "Step 840000, w: 2.6505, b: -181.8451, Loss: 10205.7684\n",
      "Step 850000, w: 2.6510, b: -182.0262, Loss: 10205.1127\n",
      "Step 860000, w: 2.6515, b: -182.2022, Loss: 10204.4926\n",
      "Step 870000, w: 2.6520, b: -182.3735, Loss: 10203.9060\n",
      "Step 880000, w: 2.6525, b: -182.5400, Loss: 10203.3513\n",
      "Step 890000, w: 2.6530, b: -182.7020, Loss: 10202.8266\n",
      "Step 900000, w: 2.6534, b: -182.8595, Loss: 10202.3304\n",
      "Step 910000, w: 2.6539, b: -183.0127, Loss: 10201.8611\n",
      "Step 920000, w: 2.6543, b: -183.1616, Loss: 10201.4172\n",
      "Step 930000, w: 2.6547, b: -183.3065, Loss: 10200.9974\n",
      "Step 940000, w: 2.6551, b: -183.4474, Loss: 10200.6003\n",
      "Step 950000, w: 2.6555, b: -183.5844, Loss: 10200.2248\n",
      "Step 960000, w: 2.6559, b: -183.7177, Loss: 10199.8696\n",
      "Step 970000, w: 2.6563, b: -183.8473, Loss: 10199.5337\n",
      "Step 980000, w: 2.6566, b: -183.9733, Loss: 10199.2160\n",
      "Step 990000, w: 2.6570, b: -184.0959, Loss: 10198.9155\n",
      "Step 1000000, w: 2.6573, b: -184.2151, Loss: 10198.6313\n",
      "Step 1010000, w: 2.6577, b: -184.3310, Loss: 10198.3625\n",
      "Step 1020000, w: 2.6580, b: -184.4438, Loss: 10198.1083\n",
      "Step 1030000, w: 2.6583, b: -184.5534, Loss: 10197.8679\n",
      "Step 1040000, w: 2.6586, b: -184.6600, Loss: 10197.6405\n",
      "Step 1050000, w: 2.6589, b: -184.7637, Loss: 10197.4254\n",
      "Step 1060000, w: 2.6592, b: -184.8646, Loss: 10197.2220\n",
      "Step 1070000, w: 2.6595, b: -184.9626, Loss: 10197.0296\n",
      "Step 1080000, w: 2.6598, b: -185.0580, Loss: 10196.8476\n",
      "Step 1090000, w: 2.6600, b: -185.1508, Loss: 10196.6755\n",
      "Step 1100000, w: 2.6603, b: -185.2410, Loss: 10196.5128\n",
      "Step 1110000, w: 2.6605, b: -185.3287, Loss: 10196.3588\n",
      "Step 1120000, w: 2.6608, b: -185.4140, Loss: 10196.2132\n",
      "Step 1130000, w: 2.6610, b: -185.4970, Loss: 10196.0755\n",
      "Step 1140000, w: 2.6612, b: -185.5777, Loss: 10195.9453\n",
      "Step 1150000, w: 2.6615, b: -185.6562, Loss: 10195.8221\n",
      "Step 1160000, w: 2.6617, b: -185.7325, Loss: 10195.7056\n",
      "Step 1170000, w: 2.6619, b: -185.8067, Loss: 10195.5954\n",
      "Step 1180000, w: 2.6621, b: -185.8789, Loss: 10195.4912\n",
      "Step 1190000, w: 2.6623, b: -185.9491, Loss: 10195.3926\n",
      "Step 1200000, w: 2.6625, b: -186.0174, Loss: 10195.2994\n",
      "Step 1210000, w: 2.6627, b: -186.0838, Loss: 10195.2112\n",
      "Step 1220000, w: 2.6629, b: -186.1483, Loss: 10195.1278\n",
      "Step 1230000, w: 2.6631, b: -186.2111, Loss: 10195.0490\n",
      "Step 1240000, w: 2.6632, b: -186.2722, Loss: 10194.9744\n",
      "Step 1250000, w: 2.6634, b: -186.3316, Loss: 10194.9038\n",
      "Step 1260000, w: 2.6636, b: -186.3894, Loss: 10194.8371\n",
      "Step 1270000, w: 2.6637, b: -186.4455, Loss: 10194.7740\n",
      "Step 1280000, w: 2.6639, b: -186.5002, Loss: 10194.7143\n",
      "Step 1290000, w: 2.6641, b: -186.5533, Loss: 10194.6579\n",
      "Step 1300000, w: 2.6642, b: -186.6049, Loss: 10194.6045\n",
      "Step 1310000, w: 2.6643, b: -186.6552, Loss: 10194.5540\n",
      "Step 1320000, w: 2.6645, b: -186.7041, Loss: 10194.5062\n",
      "Step 1330000, w: 2.6646, b: -186.7516, Loss: 10194.4610\n",
      "Step 1340000, w: 2.6648, b: -186.7978, Loss: 10194.4183\n",
      "Step 1350000, w: 2.6649, b: -186.8427, Loss: 10194.3779\n",
      "Step 1360000, w: 2.6650, b: -186.8864, Loss: 10194.3397\n",
      "Step 1370000, w: 2.6651, b: -186.9290, Loss: 10194.3036\n",
      "Step 1380000, w: 2.6653, b: -186.9703, Loss: 10194.2694\n",
      "Step 1390000, w: 2.6654, b: -187.0105, Loss: 10194.2371\n",
      "大约需要时间： 18.77251672744751 S\n"
     ]
    }
   ],
   "source": [
    "# linear regression\n",
    "b = -120\n",
    "w = -4\n",
    "# b=-2\n",
    "# w=0.01\n",
    "lr = 0.000005\n",
    "iteration = 1400000\n",
    "\n",
    "b_history = [b]\n",
    "w_history = [w]\n",
    "loss_history = []\n",
    "import time\n",
    "start = time.time()\n",
    "for i in range(iteration):\n",
    "    m = float(len(x_d))\n",
    "    y_hat = w * x_d  +b\n",
    "    loss = np.dot(y_d - y_hat, y_d - y_hat) / m\n",
    "    grad_b = -2.0 * np.sum(y_d - y_hat) / m\n",
    "    grad_w = -2.0 * np.dot(y_d - y_hat, x_d) / m\n",
    "    # update param\n",
    "    b -= lr * grad_b\n",
    "    w -= lr * grad_w\n",
    "    b_history.append(b)\n",
    "    w_history.append(w)\n",
    "    loss_history.append(loss)\n",
    "    if i % 10000 == 0:\n",
    "        print(\"Step %i, w: %0.4f, b: %.4f, Loss: %.4f\" % (i, w, b, loss))\n",
    "end = time.time()\n",
    "print(\"大约需要时间\",end-start,\"S\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 可视化结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot the figure\n",
    "plt.contourf(x, y, Z, 50, alpha=0.5, cmap=plt.get_cmap('jet'))  # 填充等高线\n",
    "plt.plot([-188.4], [2.67], 'x', ms=12, mew=3, color=\"orange\")\n",
    "plt.plot(b_history, w_history, 'o-', ms=3, lw=1.5, color='black')\n",
    "plt.xlim(-200, -100)\n",
    "plt.ylim(-5, 5)\n",
    "plt.xlabel(r'$b$')\n",
    "plt.ylabel(r'$w$')\n",
    "plt.title(\"线性回归\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e99df6600f94a5222ecb9a6a2e3edfa662ea64da68c007d01e06e6d1257b529b"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
