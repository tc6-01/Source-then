{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K近邻算法（欧氏距离）\n",
    "存在一个样本数据集合，也称作为训练样本集，并且样本集中每个数据都存在标签，即我们知道样本集中每一个数据与所属分类的对应关系。输入没有标签的新数据后，将新的数据的每个特征与样本集中数据对应的特征进行比较，然后算法提取样本最相似数据（(最近邻)计算两点之间的距离）的分类标签。一般来说，我们只选择样本数据集中前k个最相似的数据，这就是k-近邻算法中k的出处，通常k是不大于20的整数。最后，选择k个最相似数据中出现次数最多的分类，作为新数据的分类。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#创建函数集\n",
    "import numpy as np\n",
    "def createData():\n",
    "    data=np.array([[1.,101],[5.,89],[108.,5],[115.,8],[100,40]])\n",
    "    labels=['LoverView','LoverView','ActionView','ActionView','ActionView']\n",
    "    return data,labels \n",
    "    # 生成数据集以及对应的数据标签\n",
    "\n",
    "group ,labels = createData()\n",
    "print(group)\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K近邻算法步骤\n",
    "- 计算已知类别数据集中的点与当前点之间的距离；\n",
    "- 按照距离递增次序排序；\n",
    "- 选取与当前点距离最小的k个点；\n",
    "- 确定前k个点所在类别的出现频率；\n",
    "- 返回前k个点所出现频率最高的类别作为当前点的预测分类。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import operator\n",
    "def KNN(test,Train,labels,K):\n",
    "    # 获取样本个数，即属性行数\n",
    "    row = Train.shape[0]\n",
    "    # 测试集将规模扩展至训练集一致\n",
    "    ready = np.tile(test,(row,1)) - Train\n",
    "    # np.tile(array,(lay,row))将array的列复制lay次，行复制row次\n",
    "    sqDis = ready**2\n",
    "    befDis = sqDis.sum(axis=1)\n",
    "    #  axis=1行内元素相加，axis=0列内元素相加\n",
    "    Dis = befDis**0.5\n",
    "    # 开方得到欧氏距离\n",
    "    sortIndex = Dis.argsort()\n",
    "    # 返回排序后的Index\n",
    "    # 按照距离进行排序并返回对应的索引\n",
    "    classCount={}\n",
    "    # 设置字典记录出现频率\n",
    "    for i in range(K):\n",
    "        # 取出前K个元素的标记\n",
    "        label = labels[sortIndex[i]]\n",
    "        classCount[label] = classCount.get(label,0)+1\n",
    "        # 0是默认值，没有找到返回默认值\n",
    "    print(classCount)\n",
    "    sortedClassCount = sorted(classCount.items(),key=operator.itemgetter(1),reverse=True)\n",
    "    print(sortedClassCount)\n",
    "    # operator.itemgetter(1)是字典的value，operator.itemgetter(0)是字典的key\n",
    "    return sortedClassCount[0][0]\n",
    "   \n",
    "test = [40,49]\n",
    "testClass = KNN(test,group,labels,3)\n",
    "print(\"this is a\",testClass)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 完整的K-近邻算法\n",
    "- 收集数据：可以使用爬虫进行数据的收集，也可以使用第三方提供的免费或收费的数据。一般来讲，数据放在txt文本文件中，按照一定的格式进行存储，便于解析及处理。\n",
    "- 准备数据：使用Python解析、预处理数据。\n",
    "- 分析数据：可以使用很多方法对数据进行分析，例如使用Matplotlib将数据可视化。\n",
    "- 测试算法：计算错误率。\n",
    "- 使用算法：错误率在可接受范围内，就可以运行k-近邻算法进行分类。\n",
    "\n",
    "### 海伦约会实例---预测下一个特征的人会是她的理想吗？\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 读取数据\n",
    "def file2matrix(filename):\n",
    "\t#打开文件,此次应指定编码，\n",
    "    \n",
    "    fr = open(filename,'r',encoding = 'utf-8')\n",
    "\t#读取文件所有内容\n",
    "    arrayOLines = fr.readlines()\n",
    "    #针对有BOM的UTF-8文本，应该去掉BOM，否则后面会引发错误。\n",
    "    arrayOLines[0]=arrayOLines[0].lstrip('\\ufeff')\n",
    "\t#得到文件行数\n",
    "    numberOfLines = len(arrayOLines)\n",
    "\t#返回的NumPy矩阵,解析完成的数据:numberOfLines行,3列\n",
    "    returnMat = np.zeros((numberOfLines,3))\n",
    "\t#返回的分类标签向量\n",
    "    classLabelVector = []\n",
    "\t#行的索引值\n",
    "    index = 0\n",
    "\n",
    "    for line in arrayOLines:\n",
    "\t\t#s.strip(rm)，当rm空时,默认删除空白符(包括'\\n','\\r','\\t',' ')\n",
    "        line = line.strip()\n",
    "\t\t#使用s.split(str=\"\",num=string,cout(str))将字符串根据'\\t'分隔符进行切片。\n",
    "        listFromLine = line.split('\\t')\n",
    "\t\t#将数据前三列提取出来,存放到returnMat的NumPy矩阵中,也就是特征矩阵\n",
    "        returnMat[index,:] = listFromLine[0:3]\n",
    "\t\t#根据文本中标记的喜欢的程度进行分类,1代表不喜欢,2代表魅力一般,3代表极具魅力   \n",
    "\t\t# 对于datingTestSet2.txt  最后的标签是已经经过处理的 标签已经改为了1, 2, 3\n",
    "        if listFromLine[-1] == 'didntLike':\n",
    "            classLabelVector.append(1)\n",
    "        elif listFromLine[-1] == 'smallDoses':\n",
    "            classLabelVector.append(2)\n",
    "        elif listFromLine[-1] == 'largeDoses':\n",
    "            classLabelVector.append(3)\n",
    "        index += 1\n",
    "    return returnMat, classLabelVector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3, 2, 1, 1, 1, 1, 3, 3, 1, 3, 1, 1, 2, 1, 1, 1, 1, 1, 2, 3, 2, 1, 2, 3, 2, 3, 2, 3, 2, 1, 3, 1, 3, 1, 2, 1, 1, 2, 3, 3, 1, 2, 3, 3, 3, 1, 1, 1, 1, 2, 2, 1, 3, 2, 2, 2, 2, 3, 1, 2, 1, 2, 2, 2, 2, 2, 3, 2, 3, 1, 2, 3, 2, 2, 1, 3, 1, 1, 3, 3, 1, 2, 3, 1, 3, 1, 2, 2, 1, 1, 3, 3, 1, 2, 1, 3, 3, 2, 1, 1, 3, 1, 2, 3, 3, 2, 3, 3, 1, 2, 3, 2, 1, 3, 1, 2, 1, 1, 2, 3, 2, 3, 2, 3, 2, 1, 3, 3, 3, 1, 3, 2, 2, 3, 1, 3, 3, 3, 1, 3, 1, 1, 3, 3, 2, 3, 3, 1, 2, 3, 2, 2, 3, 3, 3, 1, 2, 2, 1, 1, 3, 2, 3, 3, 1, 2, 1, 3, 1, 2, 3, 2, 3, 1, 1, 1, 3, 2, 3, 1, 3, 2, 1, 3, 2, 2, 3, 2, 3, 2, 1, 1, 3, 1, 3, 2, 2, 2, 3, 2, 2, 1, 2, 2, 3, 1, 3, 3, 2, 1, 1, 1, 2, 1, 3, 3, 3, 3, 2, 1, 1, 1, 2, 3, 2, 1, 3, 1, 3, 2, 2, 3, 1, 3, 1, 1, 2, 1, 2, 2, 1, 3, 1, 3, 2, 3, 1, 2, 3, 1, 1, 1, 1, 2, 3, 2, 2, 3, 1, 2, 1, 1, 1, 3, 3, 2, 1, 1, 1, 2, 2, 3, 1, 1, 1, 2, 1, 1, 2, 1, 1, 1, 2, 2, 3, 2, 3, 3, 3, 3, 1, 2, 3, 1, 1, 1, 3, 1, 3, 2, 2, 1, 3, 1, 3, 2, 2, 1, 2, 2, 3, 1, 3, 2, 1, 1, 3, 3, 2, 3, 3, 2, 3, 1, 3, 1, 3, 3, 1, 3, 2, 1, 3, 1, 3, 2, 1, 2, 2, 1, 3, 1, 1, 3, 3, 2, 2, 3, 1, 2, 3, 3, 2, 2, 1, 1, 1, 1, 3, 2, 1, 1, 3, 2, 1, 1, 3, 3, 3, 2, 3, 2, 1, 1, 1, 1, 1, 3, 2, 2, 1, 2, 1, 3, 2, 1, 3, 2, 1, 3, 1, 1, 3, 3, 3, 3, 2, 1, 1, 2, 1, 3, 3, 2, 1, 2, 3, 2, 1, 2, 2, 2, 1, 1, 3, 1, 1, 2, 3, 1, 1, 2, 3, 1, 3, 1, 1, 2, 2, 1, 2, 2, 2, 3, 1, 1, 1, 3, 1, 3, 1, 3, 3, 1, 1, 1, 3, 2, 3, 3, 2, 2, 1, 1, 1, 2, 1, 2, 2, 3, 3, 3, 1, 1, 3, 3, 2, 3, 3, 2, 3, 3, 3, 2, 3, 3, 1, 2, 3, 2, 1, 1, 1, 1, 3, 3, 3, 3, 2, 1, 1, 1, 1, 3, 1, 1, 2, 1, 1, 2, 3, 2, 1, 2, 2, 2, 3, 2, 1, 3, 2, 3, 2, 3, 2, 1, 1, 2, 3, 1, 3, 3, 3, 1, 2, 1, 2, 2, 1, 2, 2, 2, 2, 2, 3, 2, 1, 3, 3, 2, 2, 2, 3, 1, 2, 1, 1, 3, 2, 3, 2, 3, 2, 3, 3, 2, 2, 1, 3, 1, 2, 1, 3, 1, 1, 1, 3, 1, 1, 3, 3, 2, 2, 1, 3, 1, 1, 3, 2, 3, 1, 1, 3, 1, 3, 3, 1, 2, 3, 1, 3, 1, 1, 2, 1, 3, 1, 1, 1, 1, 2, 1, 3, 1, 2, 1, 3, 1, 3, 1, 1, 2, 2, 2, 3, 2, 2, 1, 2, 3, 3, 2, 3, 3, 3, 2, 3, 3, 1, 3, 2, 3, 2, 1, 2, 1, 1, 1, 2, 3, 2, 2, 1, 2, 2, 1, 3, 1, 3, 3, 3, 2, 2, 3, 3, 1, 2, 2, 2, 3, 1, 2, 1, 3, 1, 2, 3, 1, 1, 1, 2, 2, 3, 1, 3, 1, 1, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 2, 2, 2, 3, 1, 3, 1, 2, 3, 2, 2, 3, 1, 2, 3, 2, 3, 1, 2, 2, 3, 1, 1, 1, 2, 2, 1, 1, 2, 1, 2, 1, 2, 3, 2, 1, 3, 3, 3, 1, 1, 3, 1, 2, 3, 3, 2, 2, 2, 1, 2, 3, 2, 2, 3, 2, 2, 2, 3, 3, 2, 1, 3, 2, 1, 3, 3, 1, 2, 3, 2, 1, 3, 3, 3, 1, 2, 2, 2, 3, 2, 3, 3, 1, 2, 1, 1, 2, 1, 3, 1, 2, 2, 1, 3, 2, 1, 3, 3, 2, 2, 2, 1, 2, 2, 1, 3, 1, 3, 1, 3, 3, 1, 1, 2, 3, 2, 2, 3, 1, 1, 1, 1, 3, 2, 2, 1, 3, 1, 2, 3, 1, 3, 1, 3, 1, 1, 3, 2, 3, 1, 1, 3, 3, 3, 3, 1, 3, 2, 2, 1, 1, 3, 3, 2, 2, 2, 1, 2, 1, 2, 1, 3, 2, 1, 2, 2, 3, 1, 2, 2, 2, 3, 2, 1, 2, 1, 2, 3, 3, 2, 3, 1, 1, 3, 3, 1, 2, 2, 2, 2, 2, 2, 1, 3, 3, 3, 3, 3, 1, 1, 3, 2, 1, 2, 1, 2, 2, 3, 2, 2, 2, 3, 1, 2, 1, 2, 2, 1, 1, 2, 3, 3, 1, 1, 1, 1, 3, 3, 3, 3, 3, 3, 1, 3, 3, 2, 3, 2, 3, 3, 2, 2, 1, 1, 1, 3, 3, 1, 1, 1, 3, 3, 2, 1, 2, 1, 1, 2, 2, 1, 1, 1, 3, 1, 1, 2, 3, 2, 2, 1, 3, 1, 2, 3, 1, 2, 2, 2, 2, 3, 2, 3, 3, 1, 2, 1, 2, 3, 1, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 2, 2, 2, 2, 2, 1, 3, 3, 3]\n",
      "1000\n"
     ]
    }
   ],
   "source": [
    "fr = open(\"L:/Machine-Learning/kNN/2.海伦约会/datingTestSet.txt\",'r')\n",
    "file = fr.readlines()\n",
    "length = len(file)\n",
    "# print(file,'--------')\n",
    "margtix=np.zeros((length,3))\n",
    "index =0\n",
    "classr = []\n",
    "for line in file:\n",
    "    # print(line)\n",
    "    line=line.strip()\n",
    "    line=line.split('\\t')\n",
    "    margtix[index,:]=line[0:3]\n",
    "    if line[-1] == 'didntLike':\n",
    "        classr.append(1)\n",
    "    elif line[-1] == 'smallDoses':\n",
    "        classr.append(2)\n",
    "    elif line[-1] == 'largeDoses':\n",
    "        classr.append(3)\n",
    "    index += 1\n",
    "print(classr)\n",
    "\n",
    "\n",
    "print(length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e99df6600f94a5222ecb9a6a2e3edfa662ea64da68c007d01e06e6d1257b529b"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
